{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendle_df = pd.read_json('dataset/pendle.json')\n",
    "# virtual_df = pd.read_json('virtual.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendle_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique userName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_author_names = pendle_df['author'].apply(lambda x: x.get('userName') if isinstance(x, dict) else None).dropna().unique()\n",
    "\n",
    "unique_author_names_set = set(unique_author_names)\n",
    "\n",
    "print(unique_author_names_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_author_names_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique Author Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_data = pd.json_normalize(pendle_df[\"author\"])\n",
    "\n",
    "unique_users_df = author_data.drop_duplicates(subset='userName', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping Tweets based on userNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf = pendle_df.copy()\n",
    "\n",
    "tempdf['userName'] = tempdf['author'].apply(lambda x: x.get('userName') if isinstance(x, dict) else None)\n",
    "grouped_tweets = tempdf.groupby('userName').apply(lambda x: x.to_dict(orient='records')).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tweets[\"0318Ki\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Account Engagement Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf['viewCount'].fillna(1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_cols = ['retweetCount', 'replyCount', 'likeCount', 'quoteCount', 'bookmarkCount']\n",
    "tempdf[interaction_cols] = tempdf[interaction_cols].fillna(0)\n",
    "\n",
    "# Calculate total interactions\n",
    "tempdf['totalInteractions'] = tempdf[interaction_cols].sum(axis=1)\n",
    "\n",
    "# Extract follower count\n",
    "tempdf['followers'] = tempdf['author'].apply(lambda x: x.get('followers', 1) if isinstance(x, dict) else 1)\n",
    "\n",
    "# Avoid division by zero and calculate engagement ratio\n",
    "tempdf['engagementRatio'] = tempdf['totalInteractions'] / tempdf['viewCount'].replace(0, 1)\n",
    "\n",
    "# Group by user and calculate average engagement ratio\n",
    "engagement_ratios = tempdf.groupby('userName')['engagementRatio'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement Ratio for user 0800Degen\n",
    "engagement_ratios[\"0800Degen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Account Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'createdAt' to datetime format (directly on the series)\n",
    "unique_users_df['accountCreatedAt'] = pd.to_datetime(unique_users_df['createdAt'], format=\"%a %b %d %H:%M:%S +0000 %Y\", errors='coerce')\n",
    "\n",
    "max_date = unique_users_df['accountCreatedAt'].max().date()  # Get max date only\n",
    "cutoff_date = unique_users_df[unique_users_df['accountCreatedAt'].dt.date == max_date]['accountCreatedAt'].max()\n",
    "cutoff_date = cutoff_date.tz_localize(None)  # Remove timezone if needed\n",
    "\n",
    "cutoff_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_account_age_score(df, cutoff_date):\n",
    "    df['accountCreatedAt'] = pd.to_datetime(df['createdAt'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "    # Ensure cutoff_date is a full timestamp\n",
    "    cutoff_date = cutoff_date.tz_localize(None) if cutoff_date.tz is not None else cutoff_date\n",
    "\n",
    "    # Calculate account age in days (use total_seconds for accuracy)\n",
    "    df['accountAgeDays'] = (cutoff_date - df['accountCreatedAt']).dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "    # Ensure non-negative values (in case of future dates)\n",
    "    df['accountAgeDays'] = df['accountAgeDays'].clip(lower=0)\n",
    "\n",
    "    # Calculate total days (avoid division by zero)\n",
    "    total_days = df['accountAgeDays'].max() if pd.notnull(df['accountAgeDays'].max()) else 1\n",
    "\n",
    "    # Calculate the age score\n",
    "    df['ageScore'] = df['accountAgeDays'].div(total_days).clip(upper=1).fillna(0)\n",
    "\n",
    "    # Return the scores as a dictionary\n",
    "    account_ages = df.set_index('userName')['ageScore'].to_dict()\n",
    "\n",
    "    return account_ages\n",
    "\n",
    "account_ages = calculate_account_age_score(unique_users_df, cutoff_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account Age for user 0Cyberbully\n",
    "account_ages[\"0Cyberbully\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profile Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_profile_completeness(df):\n",
    "    # Calculate completeness score with adjusted weightages\n",
    "    df['completeness_score'] = (\n",
    "        df['profilePicture'].notnull().astype(int) * 0.1 +\n",
    "        df['coverPicture'].notnull().astype(int) * 0.1 +\n",
    "        df['description'].notnull().astype(int) * 0.1 +\n",
    "        df['canDm'].astype(int) * 0.2 +\n",
    "        df['isVerified'].astype(int) * 0.5\n",
    "    )\n",
    "    \n",
    "    # Return the scores as a dictionary\n",
    "    profile_scores = df.set_index('userName')['completeness_score'].to_dict()\n",
    "    \n",
    "    return profile_scores\n",
    "\n",
    "# Calculate profile completeness scores\n",
    "profile_scores = calculate_profile_completeness(unique_users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile Completeness for user 0XunoYou\n",
    "profile_scores[\"0XunoYou\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Media Status Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_media_status_ratio(df):\n",
    "    df['mediaStatusRatio'] = df['mediaCount'].fillna(0) / (df['statusesCount'].fillna(0) + 1)\n",
    "    media_status_ratios = df.set_index('userName')['mediaStatusRatio'].to_dict()\n",
    "    return media_status_ratios\n",
    "\n",
    "# Calculate media status ratios\n",
    "media_status_ratios = calculate_media_status_ratio(unique_users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media Ratio for user 0x3bands\n",
    "media_status_ratios[\"0x3bands\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tweets[\"0318Ki\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Account frequency of tweets (daily, weekly, monthly and average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tweet_frequencies(df):\n",
    "    # Parse createdAt to datetime\n",
    "    df['tweetCreatedAt'] = pd.to_datetime(df['createdAt'], format=\"%a %b %d %H:%M:%S %z %Y\", errors='coerce')\n",
    "    \n",
    "    # Group by user\n",
    "    user_frequencies = {}\n",
    "    for user, group in df.groupby('userName'):\n",
    "        if group.empty:\n",
    "            continue\n",
    "        \n",
    "        total_tweets = len(group)\n",
    "        unique_days = group['tweetCreatedAt'].dt.date.nunique()\n",
    "        unique_weeks = group['tweetCreatedAt'].dt.isocalendar().week.nunique()\n",
    "        unique_months = group['tweetCreatedAt'].dt.to_period('M').nunique()\n",
    "        \n",
    "        min_date, max_date = group['tweetCreatedAt'].min(), group['tweetCreatedAt'].max()\n",
    "        total_days = (max_date - min_date).days + 1 if pd.notnull(min_date) and pd.notnull(max_date) else 1\n",
    "        \n",
    "        # Compute frequencies\n",
    "        daily_frequency = total_tweets / unique_days if unique_days else 0\n",
    "        weekly_frequency = total_tweets / unique_weeks if unique_weeks else 0\n",
    "        monthly_frequency = total_tweets / unique_months if unique_months else 0\n",
    "        avg_rate_of_tweets = total_tweets / total_days if total_days else 0\n",
    "        \n",
    "        # Store the result\n",
    "        user_frequencies[user] = (\n",
    "            daily_frequency,\n",
    "            weekly_frequency,\n",
    "            monthly_frequency,\n",
    "            avg_rate_of_tweets\n",
    "        )\n",
    "    \n",
    "    return user_frequencies\n",
    "\n",
    "# Calculate tweet frequencies\n",
    "account_frequency = calculate_tweet_frequencies(tempdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account Frequency(daily,weekly,monthly and average) for user AndreiMX_\n",
    "account_frequency[\"AndreiMX_\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Tweet Analysis ( persistence_score and activity_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_user_tweets(user_tweet_dict):\n",
    "    result = []\n",
    "\n",
    "    for user, tweets in user_tweet_dict.items():\n",
    "        if not tweets:\n",
    "            continue\n",
    "        \n",
    "        # Extract createdAt dates and convert to datetime\n",
    "        dates = [datetime.strptime(tweet['createdAt'], \"%a %b %d %H:%M:%S +0000 %Y\") for tweet in tweets]\n",
    "        \n",
    "        # Calculate first and last tweet dates\n",
    "        first_date = min(dates)\n",
    "        last_date = max(dates)\n",
    "        \n",
    "        # Unique active days\n",
    "        unique_active_days = len(set(date.date() for date in dates))\n",
    "        \n",
    "        # Total tweets count\n",
    "        total_tweets = len(tweets)\n",
    "        \n",
    "        # Append results\n",
    "        result.append({\n",
    "            'user_name': user,\n",
    "            'first_tweet_date': first_date,\n",
    "            'last_tweet_date': last_date,\n",
    "            'days_active': unique_active_days,\n",
    "            'total_tweets': total_tweets  # New column for tweet count\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    df['time_span'] = (df['last_tweet_date'] - df['first_tweet_date']).dt.days.replace(0, 1)  # Avoid division by zero\n",
    "    df['active_days_ratio'] = df['days_active'] / df['time_span']\n",
    "    df['tweets_per_active_day'] = df['total_tweets'] / df['days_active']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate the DataFrame\n",
    "result_df = analyze_user_tweets(grouped_tweets)\n",
    "\n",
    "# Display result\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dates_dict = result_df.set_index(\"user_name\")[[\"first_tweet_date\", \"last_tweet_date\"]].apply(tuple, axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "result_df['first_tweet_date'] = pd.to_datetime(result_df['first_tweet_date'])\n",
    "result_df['last_tweet_date'] = pd.to_datetime(result_df['last_tweet_date'])\n",
    "\n",
    "# Calculate the time span of tweets for each account\n",
    "result_df['time_span'] = (result_df['last_tweet_date'] - result_df['first_tweet_date']).dt.days\n",
    "result_df['time_span'] = result_df['time_span'].replace(0, 1)  # Avoid division by zero\n",
    "\n",
    "# Calculate persistence score\n",
    "total_days_in_dataset = (result_df['last_tweet_date'].max() - result_df['first_tweet_date'].min()).days + 1\n",
    "result_df['persistence_score'] = result_df['days_active'] / total_days_in_dataset\n",
    "\n",
    "# Calculate tweets per active day (avoid division by zero)\n",
    "result_df['tweets_per_active_day'] = result_df['total_tweets'] / result_df['days_active']\n",
    "result_df['tweets_per_active_day'] = result_df['tweets_per_active_day'].replace([float('inf'), -float('inf')], 0)\n",
    "\n",
    "# Calculate tweets per day ratio based on total dataset duration\n",
    "result_df['tweets_per_day_ratio'] = result_df['total_tweets'] / total_days_in_dataset\n",
    "\n",
    "# Compute the new activity score based on weighted values\n",
    "result_df['activity_score'] = (\n",
    "    (result_df['tweets_per_active_day'] * 0.8) +\n",
    "    (result_df['tweets_per_day_ratio'] * 0.2)\n",
    ")\n",
    "\n",
    "# Normalize the calculated activity score for comparison while preventing values from going to zero\n",
    "result_df['activity_score'] = ((result_df['activity_score'] - result_df['activity_score'].min()) / (\n",
    "    result_df['activity_score'].max() - result_df['activity_score'].min()\n",
    ")) * 0.9 + 0.1\n",
    "\n",
    "# Display the updated DataFrame\n",
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_scores = result_df.set_index(\"user_name\")[[\"persistence_score\", \"activity_score\"]].apply(tuple, axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df[\"user_name\"] == \"cz_volume\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Time between Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by user and timestamp\n",
    "sorted_df = tempdf.sort_values(by=['userName', 'tweetCreatedAt'])\n",
    "\n",
    "# Calculate the time difference between consecutive tweets\n",
    "sorted_df['timeDiff'] = sorted_df.groupby('userName')['tweetCreatedAt'].diff().dt.total_seconds() / 3600  # In hours\n",
    "\n",
    "# Calculate the average time difference per author (ignoring NaNs)\n",
    "avg_time_per_author = sorted_df.groupby('userName')['timeDiff'].mean().reset_index(name='avgTimeBetweenTweets')\n",
    "# For single tweet users the average time will be 0\n",
    "avg_time_per_author['avgTimeBetweenTweets'] = avg_time_per_author['avgTimeBetweenTweets'].fillna(0)\n",
    "\n",
    "avg_time_dict = avg_time_per_author.set_index('userName')['avgTimeBetweenTweets'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_time_dict[\"0Cyberbully\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Account's Content Originality Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_originality_ratio(df):\n",
    "    def get_tweet_score(row):\n",
    "        if row['isRetweet']:\n",
    "            score = 0\n",
    "        elif row['isReply']:\n",
    "            score = 1\n",
    "        elif row['isQuote']:\n",
    "            score = 2\n",
    "        elif not (row['isRetweet'] or row['isReply'] or row['isQuote']):\n",
    "            score = 3\n",
    "        \n",
    "        # Add media bonus\n",
    "        if row['media']:\n",
    "            score += 0.5\n",
    "        \n",
    "        return score\n",
    "\n",
    "    df['tweetScore'] = df.apply(get_tweet_score, axis=1)\n",
    "\n",
    "    # Group by username\n",
    "    grouped = df.groupby('userName').agg(\n",
    "        totalScore=('tweetScore', 'sum'),\n",
    "        totalTweets=('tweetScore', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate originality ratio\n",
    "    grouped['originalityRatio'] = grouped['totalScore'] / grouped['totalTweets']\n",
    "    \n",
    "    # Normalize the ratio between 0 and 1\n",
    "    min_ratio = grouped['originalityRatio'].min()\n",
    "    max_ratio = grouped['originalityRatio'].max()\n",
    "    \n",
    "    grouped['normalizedOriginalityRatio'] = (\n",
    "        (grouped['originalityRatio'] - min_ratio) / (max_ratio - min_ratio)\n",
    "    ).fillna(0)\n",
    "\n",
    "    result_dict = grouped.set_index('userName')['normalizedOriginalityRatio'].to_dict()\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "originality_df = tempdf.copy()\n",
    "content_originality_ratio = calculate_originality_ratio(originality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_originality_ratio[\"0800Degen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human Source Devices Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_human_device_ratio(df):\n",
    "    possible_human_source = [\n",
    "        \"Twitter Web App\",\n",
    "        \"Twitter for Android\",\n",
    "        \"Twitter for iPhone\",\n",
    "        \"Twitter for iPad\",\n",
    "        \"Twitter for Mac\",\n",
    "        \"TweetDeck\",\n",
    "        \"TweetDeck Web App\"\n",
    "    ]\n",
    "\n",
    "    human_device_ratio = {}\n",
    "    \n",
    "    for username, group in df.groupby('userName'):\n",
    "        total_tweets = len(group)\n",
    "        human_tweets = group['source'].isin(possible_human_source).sum()\n",
    "        \n",
    "        ratio = human_tweets / total_tweets if total_tweets > 0 else 0\n",
    "        \n",
    "        human_device_ratio[username] = ratio\n",
    "    \n",
    "    return human_device_ratio\n",
    "\n",
    "human_device_ratio = calculate_human_device_ratio(tempdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_device_ratio[\"0x100s\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_average_reach(df):\n",
    "#     # Group by username and calculate the average view count for each author\n",
    "#     average_reach_per_author = df.groupby('userName')['viewCount'].mean().fillna(0)\n",
    "    \n",
    "#     # Convert to a dictionary\n",
    "#     reach_dict = average_reach_per_author.to_dict()\n",
    "    \n",
    "#     return reach_dict\n",
    "\n",
    "# avg_reach = calculate_average_reach(tempdf)\n",
    "\n",
    "# Calculate average reach per author\n",
    "avg_reach_series = tempdf.groupby(\"userName\")[\"viewCount\"].mean().fillna(0)\n",
    "\n",
    "# Apply Min-Max Normalization\n",
    "avg_reach_normalized = (avg_reach_series - avg_reach_series.min()) / (avg_reach_series.max() - avg_reach_series.min())\n",
    "\n",
    "# Convert to dictionary format (if needed for further use)\n",
    "avg_reach = avg_reach_normalized.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_reach[\"0800Degen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follower to Following Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_df[\"follower_following_ratio\"] = unique_users_df[\"followers\"] / (unique_users_df[\"following\"] + 1)\n",
    "\n",
    "follower_to_following_ratio = unique_users_df.set_index('userName')['follower_following_ratio'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_df[\"follower_following_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Min-Max Normalization to follower-to-following ratio\n",
    "unique_users_df[\"follower_following_ratio_normalized\"] = (\n",
    "    (unique_users_df[\"follower_following_ratio\"] - unique_users_df[\"follower_following_ratio\"].min()) / \n",
    "    (unique_users_df[\"follower_following_ratio\"].max() - unique_users_df[\"follower_following_ratio\"].min())\n",
    ")\n",
    "\n",
    "# Convert to dictionary format (if needed)\n",
    "follower_to_following_ratio_normalized = unique_users_df.set_index(\"userName\")[\"follower_following_ratio_normalized\"].to_dict()\n",
    "\n",
    "# Display sample normalized values\n",
    "unique_users_df[[\"userName\", \"follower_following_ratio\", \"follower_following_ratio_normalized\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_df[\"follower_following_ratio_normalized\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follower_to_following_ratio[\"0800Degen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follower_to_following_ratio_normalized[\"0800Degen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Importing Pendle LLM Analysis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendle_llm = pd.read_csv(\"dataset/pendle_llm_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendle_llm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Account Emotional and Statistical Tweet Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_emotion_stat_ratio(tweet_df, analysis_df):\n",
    "    # Merge the datasets on tweet ID\n",
    "    merged_df = pd.merge(tweet_df, analysis_df, on='id')\n",
    "\n",
    "    # Group by author and calculate the emotional/statistical ratio\n",
    "    result = (\n",
    "        merged_df.groupby(merged_df['author'].apply(lambda x: x['userName']))\n",
    "        .apply(lambda group: {\n",
    "            'emotionalRatio': (group['tweet_type'] == 'emotional').mean(),\n",
    "            'statisticalRatio': (group['tweet_type'] == 'statistical').mean()\n",
    "        })\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "emotional_statistical_ratio = calculate_emotion_stat_ratio(tempdf,pendle_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_statistical_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"activity_score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_statistical_ratio[\"0800Degen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching Additional Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_df\n",
    "\n",
    "blueCheck_dict = unique_users_df.set_index(\"userName\")[[\"isBlueVerified\"]].apply(tuple, axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Making Single Day User Column and Account Activity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"single_day_user\"] = result_df[\"first_tweet_date\"].dt.date == result_df[\"last_tweet_date\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"account_activity\"] = (\n",
    "    result_df[\"activity_score\"] * 0.75 +\n",
    "    result_df[\"persistence_score\"] * 0.25 -\n",
    "    (result_df[\"single_day_user\"] * 0.05)\n",
    ")\n",
    "\n",
    "account_activity_dict = result_df.set_index(\"user_name\")[[\"account_activity\"]].apply(tuple, axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Author's Authenticity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df = pd.DataFrame({\n",
    "    'username': list(unique_author_names_set),\n",
    "    'blue_verification_badge': [blueCheck_dict.get(user, 0)[0] for user in unique_author_names_set],\n",
    "    'account_age': [account_ages.get(user, 0) for user in unique_author_names_set],\n",
    "    'profile_completeness': [profile_scores.get(user, 0) for user in unique_author_names_set],\n",
    "    'media_status_ratio': [media_status_ratios.get(user, 0) for user in unique_author_names_set],\n",
    "    'tweets_frequency': [account_activity_dict.get(user, (0, 0, 0, 0))[0] for user in unique_author_names_set],\n",
    "    'content_originality_ratio': [content_originality_ratio.get(user, 0) for user in unique_author_names_set],\n",
    "    'human_source_device_ratio': [human_device_ratio.get(user, 0) for user in unique_author_names_set],\n",
    "    'follower_to_following_ratio': [follower_to_following_ratio_normalized.get(user, 0) for user in unique_author_names_set],\n",
    "    'engagement_ratio':[engagement_ratios.get(user, 0) for user in unique_author_names_set],\n",
    "    'avg_reach': [avg_reach.get(user, 0) for user in unique_author_names_set],\n",
    "})\n",
    "\n",
    "author_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df[\"account_age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Verification Trust Score\n",
    "author_df[\"verification_trust\"] = (\n",
    "    author_df[\"blue_verification_badge\"].astype(int) * 0.20 +\n",
    "    author_df[\"account_age\"] * 0.20 +\n",
    "    author_df[\"profile_completeness\"] * 0.10 +\n",
    "    author_df[\"media_status_ratio\"] * 0.10 +\n",
    "    author_df[\"tweets_frequency\"] * 0.10 +\n",
    "    author_df[\"content_originality_ratio\"] * 0.20 +\n",
    "    author_df[\"human_source_device_ratio\"] * 0.10\n",
    ")\n",
    "\n",
    "# Calculate Follower Quality Score\n",
    "author_df[\"follower_quality\"] = (\n",
    "    author_df[\"follower_to_following_ratio\"] * 0.35 +\n",
    "    author_df[\"engagement_ratio\"] * 0.50 +\n",
    "    author_df[\"avg_reach\"] * 0.15\n",
    ")\n",
    "\n",
    "# # Normalize the scores for better ranking (Min-Max Scaling)\n",
    "author_df[\"verification_trust\"] = (author_df[\"verification_trust\"] - author_df[\"verification_trust\"].min()) / (author_df[\"verification_trust\"].max() - author_df[\"verification_trust\"].min())\n",
    "author_df[\"follower_quality\"] = (author_df[\"follower_quality\"] - author_df[\"follower_quality\"].min()) / (author_df[\"follower_quality\"].max() - author_df[\"follower_quality\"].min())\n",
    "\n",
    "# Calculate final Ranking Score\n",
    "author_df[\"ranking_score\"] = author_df[\"verification_trust\"] * 0.40 + author_df[\"follower_quality\"] * 0.60\n",
    "\n",
    "# Sort by ranking_score in descending order\n",
    "author_df_sorted = author_df.sort_values(by=\"ranking_score\", ascending=False)\n",
    "\n",
    "# Display top 5 ranked accounts\n",
    "author_df_sorted[[\"username\", \"verification_trust\", \"follower_quality\", \"ranking_score\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df.to_csv(\"ranked_author.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
